<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Métodos y Simulación Estadística" />


<title> Residuales</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"> </a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Métodos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Contenido</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Correlación
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso100.html">Análisis de Correlación</a>
    </li>
    <li>
      <a href="recurso110.html">Coeficiente de Pearson</a>
    </li>
    <li>
      <a href="recurso120.html">Coeficiente de Spearman</a>
    </li>
    <li>
      <a href="recurso130.html">Coeficiente de Kendall</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Modelo
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso200.html">Modelo de Regresión Lineal Simple</a>
    </li>
    <li>
      <a href="recurso210.html">Estimación Mínimos Cuadrados Ordinarios</a>
    </li>
    <li>
      <a href="recurso220.html">Estimación de Máxima Verosimilitud</a>
    </li>
    <li>
      <a href="recurso230.html">Forma Matricial del Modelo</a>
    </li>
    <li>
      <a href="recurso300.html">Supuestos</a>
    </li>
    <li>
      <a href="recurso310.html">Residuales</a>
    </li>
    <li>
      <a href="recurso320.html">Revisión de Supuestos</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tests y R Cuadrado
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso400.html">Pruebas de Hipótesis</a>
    </li>
    <li>
      <a href="recurso410.html">R Cuadrado</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Transformaciones
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso500.html">Transformaciones</a>
    </li>
    <li>
      <a href="recurso600.html">Modelos Polinomiales</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Predicción e Intervalos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso700.html">Intervalo de Confianza</a>
    </li>
    <li>
      <a href="recurso800.html">Intervalos de C. de Coeficientes y Varianza</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Atípicos e Influyentes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso900.html">Punto Atípico e Influyente</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tablero
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso1000.html">Tablero usando Shiny</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Referencias
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="recurso2000.html">Referencias</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore"><span style="color:#686868">
<strong>Residuales</strong></span></h1>
<h4 class="author">Métodos y Simulación Estadística</h4>

</div>


</br></br>
<h2>
Introducción
</h2>
<p>Los <strong>residuales</strong> o <strong>residuos</strong> en
regresión son herramientas fundamentales para evaluar si los supuestos
del modelo se cumplen y detectar posibles problemas en los datos.
Existen varios tipos de residuales, cada uno con un propósito
específico:</p>
<ul>
<li><p>El <strong>residual ordinario</strong> es la diferencia directa
entre los valores observados y los predichos por el modelo.</p></li>
<li><p>Los <strong>residuales estandarizados y studentizados</strong>
ayudan a identificar <strong>valores atípicos</strong>, ajustando la
escala de los residuales para hacerlos comparables.</p></li>
<li><p>El <strong>residual PRESS</strong> es útil en <strong>validación
cruzada</strong>, ya que evalúa el impacto de cada observación en la
predicción al excluirla del ajuste.</p></li>
</ul>
</br></br>
<h2>
Tipos de residuales en modelos de regresión
</h2>
<p>Para comprender mejor estos residuales, es importante conocer algunos
conceptos clave:</p>
<ul>
<li><p><strong>Peso <span class="math inline">\(W_i\)</span></strong>:
Indica la importancia de cada observación en el modelo. En modelos sin
ponderación, se asume <span class="math inline">\(W_i =
1\)</span>.</p></li>
<li><p><strong>Leverage <span
class="math inline">\(h_{ii}\)</span></strong>: Representa la influencia
de la observación <span class="math inline">\(i\)</span> en su propia
predicción. Se obtiene a partir de la <strong>matriz sombrero</strong> o
<strong>hat matrix</strong> que se determina con la matriz de diseño
<span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
H = X (X^\top X)^{-1} X^\top.
\]</span></p>
<p>Valores altos de <span class="math inline">\(h_{ii}\)</span> sugieren
que una observación tiene un impacto significativo en la estimación de
los coeficientes y en la predicción.</p></li>
<li><p><strong>Varianza ajustada <span
class="math inline">\(\hat{\sigma}^2_{(i)}\)</span></strong>: Es la
estimación de la varianza de los errores cuando <strong>se
excluye</strong> la observación <span class="math inline">\(i\)</span>.
Se utiliza para evaluar la estabilidad del modelo ante la eliminación de
datos individuales.</p></li>
<li><p><strong>Estimación <span
class="math inline">\(\hat{y}_{(i)}\)</span></strong>: Representa la
predicción de <span class="math inline">\(y_i\)</span> en un modelo
ajustado <strong>sin incluir la observación <span
class="math inline">\(i\)</span></strong>. Su cálculo es clave en
métodos de validación cruzada, como el residual PRESS.</p></li>
</ul>
<p>El análisis de los distintos tipos de residuales permite detectar
<strong>valores atípicos, puntos influyentes y problemas de
ajuste</strong> en el modelo. Comprender cómo estos residuales se
calculan e interpretan es fundamental para garantizar la validez del
modelo de regresión y mejorar su capacidad predictiva.</p>
<hr />
</br></br>
<h3>
Residual ordinario
</h3>
<p>El <strong>residual ordinario</strong> mide la diferencia entre el
valor observado <span class="math inline">\(y_i\)</span> y el valor
predicho <span class="math inline">\(\hat{y}_i\)</span>, es decir,
representa el error de predicción para cada observación en el modelo de
regresión.</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i
\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(e_i\)</span> es el <strong>residual
ordinario</strong> para la observación <span
class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(y_i\)</span> es el <strong>valor
observado</strong> de la variable respuesta.</p></li>
<li><p><span class="math inline">\(\hat{y}_i\)</span> es el
<strong>valor ajustado (predicho)</strong> por el modelo de
regresión.</p></li>
</ul>
<p>Los residuales ordinarios permiten evaluar la <strong>precisión del
modelo</strong>, ya que indican qué tan lejos están las predicciones de
los valores reales. Cuando los residuos presentan un comportamiento
aleatorio, sugiere que el modelo es adecuado; sin embargo,
<strong>patrones sistemáticos en los residuales pueden indicar problemas
en la especificación del modelo</strong>.</p>
</br></br>
<h3>
Residual de Pearson
</h3>
<p>El <strong>residual de Pearson</strong> es una versión ponderada del
<strong>residual ordinario</strong>, que ajusta la diferencia entre los
valores observados y predichos utilizando un factor de ponderación <span
class="math inline">\(W_i\)</span>:</p>
<p><span class="math display">\[
p_i = e_i \sqrt{W_i}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(p_i\)</span> es el <strong>residual
de Pearson</strong> para la observación <span
class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(e_i\)</span> es el <strong>residual
ordinario</strong>: <span class="math inline">\(e_i = y_i -
\hat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(W_i\)</span> representa el
<strong>peso o importancia de cada observación</strong> en el
modelo.</p></li>
</ul>
<p>En modelos de <strong>regresión lineal ordinaria</strong>, se asume
que <strong>todas las observaciones tienen el mismo peso</strong>, es
decir, <span class="math inline">\(W_i = 1\)</span>. Sin embargo, en
modelos de regresión ponderada, los pesos pueden variar para dar mayor o
menor importancia a ciertas observaciones.</p>
<p>El residual de Pearson se usa comúnmente en <strong>modelos de
regresión generalizada</strong> (GLM) para evaluar el ajuste del modelo
cuando las varianzas de los errores no son constantes.</p>
</br></br>
<h3>
Residual estandarizado
</h3>
<p>El <strong>residual estandarizado</strong> es una versión ajustada
del <strong>residual ordinario</strong>, que toma en cuenta la
<strong>variabilidad de los errores</strong> y la <strong>influencia de
cada observación</strong> en el modelo. Se define como:</p>
<p><span class="math display">\[
d_i = \frac{e_i \sqrt{W_i}}{\sqrt{\hat{\sigma}^2 (1 - h_{ii})}}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(d_i\)</span> es el <strong>residual
estandarizado</strong> para la observación <span
class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(e_i\)</span> es el <strong>residual
ordinario</strong>: <span class="math inline">\(e_i = y_i -
\hat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(W_i\)</span> es el <strong>peso de la
observación <span class="math inline">\(i\)</span></strong>. En
regresión lineal ordinaria, <span class="math inline">\(W_i =
1\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{\sigma}^2\)</span> es la
<strong>varianza estimada del error</strong> en el modelo.</p></li>
<li><p><span class="math inline">\(h_{ii}\)</span> es el
<strong>leverage</strong>, es decir, la influencia de la observación
<span class="math inline">\(i\)</span> en su propia predicción.</p></li>
</ul>
<p>Este residual ajusta la escala de los errores en función de la
<strong>influencia de cada observación en el modelo</strong>. Es útil
para identificar <strong>valores atípicos</strong>, ya que valores
absolutos grandes de <span class="math inline">\(d_i\)</span> sugieren
que una observación se aleja significativamente del patrón general del
modelo.</p>
</br></br>
<h3>
Residual studentizado
</h3>
<p>El <strong>residual studentizado</strong> es una versión ajustada del
<strong>residual estandarizado</strong>, en la que se estima la varianza
del error <strong>sin incluir la observación <span
class="math inline">\(i\)</span></strong>. Esto permite una evaluación
más robusta de la influencia de cada observación y facilita la detección
de <strong>valores atípicos</strong>.</p>
<p><span class="math display">\[
r_i = \frac{e_i \sqrt{W_i}}{\sqrt{\hat{\sigma}^2_{(i)} (1 - h_{ii})}}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(r_i\)</span> es el <strong>residual
studentizado</strong> para la observación <span
class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(e_i\)</span> es el <strong>residual
ordinario</strong>: <span class="math inline">\(e_i = y_i -
\hat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(W_i\)</span> es el <strong>peso de la
observación <span class="math inline">\(i\)</span></strong>. En
regresión lineal ordinaria, <span class="math inline">\(W_i =
1\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{\sigma}^2_{(i)}\)</span> es la
<strong>varianza del error estimada sin incluir la observación <span
class="math inline">\(i\)</span></strong>.</p></li>
<li><p><span class="math inline">\(h_{ii}\)</span> es el
<strong>leverage</strong>, que mide la influencia de la observación
<span class="math inline">\(i\)</span> en su propia predicción.</p></li>
</ul>
<p>El <strong>residual studentizado</strong> se usa principalmente para
<strong>detectar valores atípicos de manera más precisa</strong>, ya que
el cálculo de la varianza excluyendo la observación <span
class="math inline">\(i\)</span> reduce el impacto de valores extremos
en la estimación de <span class="math inline">\(\sigma^2\)</span>.</p>
<p>En modelos bien ajustados con errores normales, se espera que la
mayoría de los valores de <span class="math inline">\(r_i\)</span> estén
dentro del rango <span class="math inline">\([-2,2]\)</span>. Valores
absolutos mayores a <strong>3</strong> sugieren que la observación <span
class="math inline">\(i\)</span> podría ser <strong>un valor atípico
significativo</strong>. A diferencia del residual estandarizado, este
residual es más confiable para detectar valores extremos, ya que ajusta
la varianza sin depender de la observación analizada.</p>
<p>Este tipo de residual es una herramienta clave en
<strong>diagnósticos de regresión</strong>, especialmente cuando se
busca identificar puntos que podrían afectar sustancialmente la
estimación de los coeficientes del modelo.</p>
</br></br>
<h3>
Residual parcial
</h3>
<p>El <strong>residual parcial</strong> se obtiene eliminando una de las
columnas de la matriz de diseño <span class="math inline">\(X\)</span> y
recalculando los residuales en el modelo modificado. Su principal
utilidad radica en la <strong>regresión lineal múltiple</strong>, donde
permite evaluar el impacto individual de una variable predictora en la
variable respuesta.</p>
<p>Este residual se expresa matemáticamente como:</p>
<p><span class="math display">\[
e_{p,i} = Y_i - \hat{Y}_i^{(-j)}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(e_{p,i}\)</span> es el
<strong>residual parcial</strong> de la observación <span
class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(Y_i\)</span> es el <strong>valor
observado</strong> de la variable respuesta.</p></li>
<li><p><span class="math inline">\(\hat{Y}_i^{(-j)}\)</span> es el
<strong>valor ajustado</strong> para <span
class="math inline">\(Y_i\)</span> en un modelo donde la variable
predictora <span class="math inline">\(X_j\)</span> ha sido
eliminada.</p></li>
</ul>
<p>En <strong>regresión múltiple</strong>, cada predictor <span
class="math inline">\(X_j\)</span> puede estar asociado con otras
variables del modelo. El <strong>residual parcial</strong> permite
aislar el efecto de <span class="math inline">\(X_j\)</span> sobre <span
class="math inline">\(Y\)</span> y evaluar si su inclusión en el modelo
mejora la predicción.</p>
<p>Este tipo de residual es especialmente útil para:</p>
<ul>
<li><p><strong>Evaluar la importancia de una variable
predictora</strong> en el modelo.</p></li>
<li><p><strong>Detectar colinealidad</strong>, observando cómo cambia el
ajuste al eliminar una variable.</p></li>
<li><p><strong>Analizar la relación marginal entre <span
class="math inline">\(X_j\)</span> y <span
class="math inline">\(Y\)</span></strong>, ignorando el efecto de otras
variables.</p></li>
</ul>
<p>Si los <strong>residuales parciales son grandes</strong>, significa
que la variable eliminada tenía un impacto significativo en la
predicción. Si los residuales no muestran un patrón claro, la variable
eliminada puede no estar contribuyendo significativamente al modelo.</p>
<p>Los <strong>gráficos de residuales parciales</strong> permiten
visualizar la relación entre una variable predictora específica y la
respuesta, lo que facilita la toma de decisiones sobre la inclusión o
exclusión de predictores en el modelo.</p>
</br></br>
<h3>
Residual PRESS (Prediction Residual Sum of Squares)
</h3>
<p>El <strong>residual PRESS</strong> mide la diferencia entre el valor
observado <span class="math inline">\(y_i\)</span> y el valor predicho
<span class="math inline">\(\hat{y}_{(i)}\)</span>, donde <strong><span
class="math inline">\(\hat{y}_{(i)}\)</span> es la estimación de <span
class="math inline">\(y_i\)</span> sin usar la observación <span
class="math inline">\(i\)</span> en el ajuste del modelo</strong>. Este
residual es clave en la <strong>validación cruzada leave-one-out
(LOO)</strong>, ya que evalúa cómo se comportaría el modelo si la
observación <span class="math inline">\(i\)</span> no hubiera sido
incluida en su entrenamiento.</p>
<p><span class="math display">\[
e_{(i)} = y_i - \hat{y}_{(i)} = \frac{e_i}{1 - h_{ii}}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(e_{(i)}\)</span> es el
<strong>residual PRESS</strong> para la observación <span
class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(e_i\)</span> es el <strong>residual
ordinario</strong>: <span class="math inline">\(e_i = y_i -
\hat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(h_{ii}\)</span> es el
<strong>leverage</strong>, que mide la influencia de la observación
<span class="math inline">\(i\)</span> en su propia predicción.</p></li>
</ul>
<p></br> Este residual se usa para calcular la <strong>suma de los
cuadrados de los errores de predicción (PRESS)</strong>:</p>
<p><span class="math display">\[
  PRESS = \sum_{i=1}^{n} e_{(i)}^2
  \]</span></p>
<p>Un menor valor de <strong>PRESS</strong> indica un modelo con mejor
capacidad de <strong>predicción</strong> en datos nuevos. Es útil para
<strong>detectar observaciones influyentes</strong>, ya que valores
grandes de <span class="math inline">\(e_{(i)}\)</span> pueden indicar
que una observación tiene un impacto significativo en el ajuste del
modelo.</p>
<p>Si <span class="math inline">\(e_{(i)}\)</span> es grande en valor
absoluto, significa que la observación <span
class="math inline">\(i\)</span> <strong>es difícil de predecir</strong>
sin incluirla en el modelo, lo que sugiere que podría ser un
<strong>valor atípico o influyente</strong>. Valores pequeños de <span
class="math inline">\(e_{(i)}\)</span> sugieren que la observación <span
class="math inline">\(i\)</span> <strong>no afecta significativamente la
predicción</strong> y que el modelo es <strong>estable</strong> ante su
eliminación.</p>
<hr />
</br></br>
<h2>
Funciones en <strong>R</strong> para obtener residuales
</h2>
<p>Para obtener los distintos tipos de residuales en <strong>R</strong>,
se pueden utilizar las siguientes funciones:</p>
<pre>
# Residuales generales
residuals(object, type = c("working", "response", "deviance", "pearson", "partial"))

# Residuales estandarizados
rstandard(object)

# Residuales studentizados
rstudent(object)
</pre>
</br></br>
<div class="caja-ejemplo">
<h3>
Ejemplo:
</h3>
<p>
<p>El objetivo es ajustar un <strong>modelo de regresión lineal
ponderada</strong>, donde la <strong>media de <span
class="math inline">\(Y\)</span></strong> se modela en función de <span
class="math inline">\(X\)</span>, utilizando como pesos los valores de
<span class="math inline">\(W\)</span>. Una vez ajustado el modelo, se
procederá a calcular los <strong>valores ajustados</strong> y los
<strong>residuales manualmente</strong>, comparándolos posteriormente
con los obtenidos mediante las funciones de <strong>R</strong>.</p>
<p>En este análisis, se dispone de informaciónsobre la variable
respuesta (<span class="math inline">\(Y\)</span>), la variable
predictora (<span class="math inline">\(X\)</span>) y los pesos
asociados (<span class="math inline">\(W\)</span>).</p>
<p>Los datos correspondientes están disponibles en el siguiente
enlace:</p>
<p><a
href="https://raw.githubusercontent.com/smramirezb/datos_ejemplos/refs/heads/main/dat_res.txt">Descargar
datos de <span class="math inline">\(Y\)</span>, <span
class="math inline">\(X\)</span> y <span
class="math inline">\(W\)</span></a></p>
<p>Para realizar este ajuste en <strong>R</strong>, se emplea la función
<code>lm()</code> especificando el argumento <code>weights = w</code>,
lo que permite asignar diferentes pesos a cada observación en el modelo
de regresión.</p>
<p>Los <strong>coeficientes estimados</strong> mediante el ajuste del
modelo definen la ecuación de la <strong>regresión lineal
ponderada</strong>:</p>
<p><span class="math display">\[
\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i
\]</span></p>
<p><strong>Cálculo manual de los valores ajustados y
residuales:</strong></p>
<p>Dado que la regresión es <strong>ponderada</strong>, los valores
ajustados y los <strong>residuales ordinarios</strong> se calculan de la
siguiente manera:</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i
\]</span></p>
<p><span class="math display">\[
p_i = e_i \sqrt{w_i} \quad \text{(Residual de Pearson)}
\]</span></p>
<p><span class="math display">\[
r_i = \frac{e_i \sqrt{w_i}}{\sqrt{\hat{\sigma}^2 (1 - h_{ii})}} \quad
\text{(Residual Estandarizado)}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(e_i\)</span> es el <strong>residual
ordinario</strong>, que representa la diferencia entre el valor
observado <span class="math inline">\(y_i\)</span> y el valor ajustado
<span class="math inline">\(\hat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(p_i\)</span> es el <strong>residual
de Pearson</strong>, que ajusta la magnitud del error en función del
peso <span class="math inline">\(w_i\)</span>, permitiendo evaluar la
adecuación del modelo cuando las observaciones tienen varianzas
heterogéneas.</p></li>
<li><p><span class="math inline">\(r_i\)</span> es el <strong>residual
estandarizado</strong>, el cual ajusta el error considerando tanto la
varianza estimada <span class="math inline">\(\hat{\sigma}^2\)</span>
como el leverage <span class="math inline">\(h_{ii}\)</span>,
proporcionando una métrica útil para la detección de valores
atípicos.</p></li>
</ul>
<pre>
# Lectura de datos
file <- "https://raw.githubusercontent.com/smramirezb/datos_ejemplos/refs/heads/main/dat_res.txt"
datos <- read.table(file = file, header = TRUE)

x<-datos$x
y<-datos$y
w<-datos$w


#  Ajuste del Modelo de Regresión Lineal Ponderada 
# Se ajusta el modelo de regresión ponderada usando los valores de 'w' como pesos
modelo_ponderado <- lm(y ~ x, weights = w)  

# Se pueden visualizar los resultados del modelo con:
summary(modelo_ponderado)

# Extraer Coeficientes del Modelo 
# Se obtienen los coeficientes estimados del modelo ajustado
beta_0 <- coef(modelo_ponderado)[1]  # Intercepto estimado
beta_1 <- coef(modelo_ponderado)[2]  # Pendiente estimada

# Cálculo de los Valores Ajustados Manualmente 
# Se calculan los valores ajustados manualmente utilizando la ecuación del modelo
y_hat_manual <- beta_0 + beta_1 * x  

# Cálculo de los Residuales 
# Los residuales ordinarios representan la diferencia entre los valores observados y los valores ajustados
residuales_ordinarios <- y - y_hat_manual  

# Cálculo de los Residuales de Pearson
# Los residuales de Pearson ajustan el error ordinario usando la raíz cuadrada del peso
residuales_pearson_manual <- residuales_ordinarios * sqrt(w) 

# Crear una Tabla con los Resultados 
# Se crea un data frame con las variables, predicciones y residuales
resultados <- data.frame(
  X = x,
  Y = y,
  Pesos = w,
  Predicciones = y_hat_manual,
  Residuales_Ordinarios = residuales_ordinarios,
  Residuales_Pearson = residuales_pearson_manual
)

# Mostrar la tabla con los resultados
print(resultados)
</pre>
<pre class="r"><code># Lectura de datos
file &lt;- &quot;https://raw.githubusercontent.com/smramirezb/datos_ejemplos/refs/heads/main/dat_res.txt&quot;
datos &lt;- read.table(file = file, header = TRUE)

x&lt;-datos$x
y&lt;-datos$y
w&lt;-datos$w


#  Ajuste del Modelo de Regresión Lineal Ponderada 
# Se ajusta el modelo de regresión ponderada usando los valores de &#39;w&#39; como pesos
modelo_ponderado &lt;- lm(y ~ x, weights = w)  

# Se pueden visualizar los resultados del modelo con:
summary(modelo_ponderado)

# Extraer Coeficientes del Modelo 
# Se obtienen los coeficientes estimados del modelo ajustado
beta_0 &lt;- coef(modelo_ponderado)[1]  # Intercepto estimado
beta_1 &lt;- coef(modelo_ponderado)[2]  # Pendiente estimada

# Cálculo de los Valores Ajustados Manualmente 
# Se calculan los valores ajustados manualmente utilizando la ecuación del modelo
y_hat_manual &lt;- beta_0 + beta_1 * x  

# Cálculo de los Residuales 
# Los residuales ordinarios representan la diferencia entre los valores observados y los valores ajustados
residuales_ordinarios &lt;- y - y_hat_manual  

# Cálculo de los Residuales de Pearson 
# Los residuales de Pearson ajustan el error ordinario usando la raíz cuadrada del peso
residuales_pearson_manual &lt;- residuales_ordinarios * sqrt(w) 

# Crear una Tabla con los Resultados 
# Se crea un data frame con las variables, predicciones y residuales
resultados &lt;- data.frame(
  X = x,
  Y = y,
  Pesos = w,
  Predicciones = y_hat_manual,
  Residuales_Ordinarios = residuales_ordinarios,
  Residuales_Pearson = residuales_pearson_manual
)

# Mostrar la tabla con los resultados
print(resultados)</code></pre>
<p>Los resultados de los <strong>residuales ordinarios</strong> y de
<strong>Pearson</strong> son los siguientes:</p>
<pre>
   X Y Pesos Predicciones Residuales_Ordinarios Residuales_Pearson
1 4 1   0.1     3.348739            -2.3487395        -0.74273664
2 6 2   0.1     3.710084            -1.7100840        -0.54077605
3 8 3   0.2     4.071429            -1.0714286        -0.47915742
4 7 4   0.1     3.890756             0.1092437         0.03454589
5 8 5   0.2     4.071429             0.9285714         0.41526977
6 5 4   0.9     3.529412             0.4705882         0.44643920
</pre>
<p>Para comprobar que los cálculos manuales de los valores ajustados y
los residuales coinciden con los obtenidos por las funciones de
<strong>R</strong>, se realiza la siguiente comparación:</p>
<pre>
# Lectura de datos
file <- "https://raw.githubusercontent.com/smramirezb/datos_ejemplos/refs/heads/main/dat_res.txt"
datos <- read.table(file = file, header = TRUE)

x<-datos$x
y<-datos$y
w<-datos$w

# Ajuste del Modelo de Regresión Lineal Ponderada 
# Se ajusta un modelo de regresión lineal ponderada usando 'w' como pesos
modelo_ponderado <- lm(y ~ x, weights = w)  

# Obtención de Valores Ajustados y Residuales 
# Valores ajustados (predicciones) obtenidos a partir del modelo ajustado por R
y_hat_r <- fitted(modelo_ponderado)

# Residuales ordinarios: Diferencia entre valores observados y valores ajustados
residuales_r <- residuals(modelo_ponderado)

# Residuales de Pearson: Residuales ordinarios escalados por la varianza estimada
residuales_pearson_r <- residuals(modelo_ponderado, type = "pearson")

# Comparación de Resultados Manuales y de R 
# Se verifica si los cálculos manuales coinciden con los generados por R

comparacion_resultados <- data.frame(
  X = x,
  Y = y,
  Pesos = w,
  Predicciones_Manual = y_hat_manual,  # Predicciones calculadas manualmente
  Predicciones_R = y_hat_r,  # Predicciones generadas por R
  Residuales_Ordinarios_Manual = residuales_ordinarios,  # Residuales ordinarios manuales
  Residuales_R = residuales_r,  # Residuales ordinarios generados por R
  Residuales_Pearson_Manual = residuales_pearson_manual,  # Residuales de Pearson manuales
  Residuales_Pearson_R = residuales_pearson_r  # Residuales de Pearson generados por R
)

# Mostrar la tabla con la comparación de resultados
print(comparacion_resultados)
</pre>
<pre class="r"><code># Lectura de datos
file &lt;- &quot;https://raw.githubusercontent.com/smramirezb/datos_ejemplos/refs/heads/main/dat_res.txt&quot;
datos &lt;- read.table(file = file, header = TRUE)

x&lt;-datos$x
y&lt;-datos$y
w&lt;-datos$w

# Ajuste del Modelo de Regresión Lineal Ponderada 
# Se ajusta un modelo de regresión lineal ponderada usando &#39;w&#39; como pesos
modelo_ponderado &lt;- lm(y ~ x, weights = w)  

# Obtención de Valores Ajustados y Residuales 
# Valores ajustados (predicciones) obtenidos a partir del modelo ajustado por R
y_hat_r &lt;- fitted(modelo_ponderado)

# Residuales ordinarios: Diferencia entre valores observados y valores ajustados
residuales_r &lt;- residuals(modelo_ponderado)

# Residuales de Pearson: Residuales ordinarios escalados por la varianza estimada
residuales_pearson_r &lt;- residuals(modelo_ponderado, type = &quot;pearson&quot;)

# Comparación de Resultados Manuales y de R 
# Se verifica si los cálculos manuales coinciden con los generados por R

comparacion_resultados &lt;- data.frame(
  X = x,
  Y = y,
  Pesos = w,
  Predicciones_Manual = y_hat_manual,  # Predicciones calculadas manualmente
  Predicciones_R = y_hat_r,  # Predicciones generadas por R
  Residuales_Ordinarios_Manual = residuales_ordinarios,  # Residuales ordinarios manuales
  Residuales_R = residuales_r,  # Residuales ordinarios generados por R
  Residuales_Pearson_Manual = residuales_pearson_manual,  # Residuales de Pearson manuales
  Residuales_Pearson_R = residuales_pearson_r  # Residuales de Pearson generados por R
)

# Mostrar la tabla con la comparación de resultados
print(comparacion_resultados)</code></pre>
<p>Los resultados de la implementación manual y con <strong>R</strong>
es la siguiente:</p>
<pre>
  X Y Pesos Predicciones_Manual Predicciones_R Residuales_Ordinarios_Manual Residuales_R Residuales_Pearson_Manual Residuales_Pearson_R
1 4 1   0.1            3.348739       3.348739                   -2.3487395   -2.3487395               -0.74273664          -0.74273664
2 6 2   0.1            3.710084       3.710084                   -1.7100840   -1.7100840               -0.54077605          -0.54077605
3 8 3   0.2            4.071429       4.071429                   -1.0714286   -1.0714286               -0.47915742          -0.47915742
4 7 4   0.1            3.890756       3.890756                    0.1092437    0.1092437                0.03454589           0.03454589
5 8 5   0.2            4.071429       4.071429                    0.9285714    0.9285714                0.41526977           0.41526977
6 5 4   0.9            3.529412       3.529412                    0.4705882    0.4705882                0.44643920           0.44643920
</pre>
<hr />
<p><strong>Regresión ponderada:</strong></p>
<p>En una <strong>regresión ponderada</strong>, los
<strong>pesos</strong> asignados a cada observación determinan la
influencia que tiene cada punto en la estimación de los coeficientes del
modelo. Estos pesos permiten ajustar la importancia de cada observación,
lo que es útil cuando los datos presentan heterocedasticidad
(variabilidad no constante) o cuando algunas mediciones son más
confiables que otras.</p>
<p>Los pesos <span class="math inline">\(w_i\)</span> pueden
interpretarse de diferentes maneras según el contexto del problema:</p>
<ul>
<li><p><strong>Como la inversa de la varianza de los
errores</strong>:</p>
<p><span class="math display">\[
w_i = \frac{1}{\sigma_i^2}
\]</span></p>
<p>Donde <span class="math inline">\(\sigma_i^2\)</span> representa la
varianza del error para la observación <span
class="math inline">\(i\)</span>. En este caso, se otorgan
<strong>mayores pesos</strong> a las observaciones con menor
variabilidad y <strong>menores pesos</strong> a las observaciones con
alta dispersión.</p></li>
<li><p><strong>Como una función de la confiabilidad de la
observación</strong>:</p>
<ul>
<li><p>Las observaciones con <strong>alta precisión</strong> reciben
<strong>mayor peso</strong>, influyendo más en la estimación del
modelo.</p></li>
<li><p>Las observaciones con <strong>mayor variabilidad o ruido</strong>
tienen <strong>menor peso</strong>, reduciendo su impacto en el
ajuste.</p></li>
</ul></li>
</ul>
</p>
</div>
<div class="caja-actividad">
<h3>
Nota:
</h3>
<blockquote>
<p>
<strong>Caso especial</strong>: Si todos los pesos son iguales
<strong>(<span class="math inline">\(w_i = 1\)</span></strong> para
todas las observaciones), la regresión ponderada <strong>equivale a la
regresión lineal ordinaria</strong>.
</p>
</blockquote>
</div>
<div class="caja-actividad">
<h3>
Actividad:
</h3>
<blockquote>
<p>
<ul>
<li>Repite el ejemplo anterior considerando una regresión lineal simple
ordinaria. Compara los distintos tipos de residuales.</li>
</ul>
</p>
</blockquote>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
