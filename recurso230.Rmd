---
title: <span style="color:#686868"> **Forma matricial del modelo**</span>
author: "Métodos y Simulación Estadística"
output:
  html_document:
    code_folding: hide
    css: style.css
---

</br></br>
<h2>Regresión lineal simple en forma matricial</h2>

La formulación matricial del modelo de **regresión lineal simple** permite expresar el problema de manera compacta y eficiente. Esto facilita la estimación de los coeficientes, el cálculo de valores ajustados y el análisis de los residuales.



La **regresión lineal simple** en forma matricial se expresa como:  

\[
\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}
\]

donde:  

- \( \mathbf{Y} \) es el **vector de respuesta** de dimensión \( n \times 1 \), que contiene las observaciones de la variable dependiente. 

- \( \mathbf{X} \) es la **matriz de diseño** de dimensión \( n \times 2 \), que incluye una columna de unos (para el intercepto) y una columna con los valores de la variable independiente.  

- \( \boldsymbol{\beta} \) es el **vector de coeficientes** de dimensión \( 2 \times 1 \), que contiene el intercepto \( \beta_0 \) y la pendiente \( \beta_1 \).  

- \( \boldsymbol{\varepsilon} \) es el **vector de errores** de dimensión \( n \times 1 \).


</br></br>
<h3>Matriz de diseño \( \mathbf{X} \)</h3>



\[
\mathbf{X} =
\begin{bmatrix}
1 & X_1 \\
1 & X_2 \\
\vdots & \vdots \\
1 & X_n
\end{bmatrix}
\]

La primera columna es de unos para representar el intercepto \( \beta_0 \), y la segunda columna contiene los valores de la variable independiente \( X \).


</br></br>
<h3>Vector de coeficientes \( \boldsymbol{\beta} \)</h3>


\[
\boldsymbol{\beta} =
\begin{bmatrix}
\beta_0 \\
\beta_1
\end{bmatrix}
\]

Este vector contiene los parámetros del modelo, que deben estimarse a partir de los datos.


</br></br>
<h3>Vector de respuesta \( \mathbf{Y} \)</h3>


\[
\mathbf{Y} =
\begin{bmatrix}
Y_1 \\
Y_2 \\
\vdots \\
Y_n
\end{bmatrix}
\]

Este es el vector de valores observados de la variable dependiente.


</br></br>
<h3>Vector de errores \( \boldsymbol{\varepsilon} \)</h3>


\[
\boldsymbol{\varepsilon} =
\begin{bmatrix}
\varepsilon_1 \\
\varepsilon_2 \\
\vdots \\
\varepsilon_n
\end{bmatrix}
\]

Los errores representan la diferencia entre los valores observados \( Y_i \) y la verdadera relación lineal de la población. **No son observables**, ya que dependen de los coeficientes poblacionales \( \beta_0 \) y \( \beta_1 \), que son desconocidos.


</br></br>
<h3>Estimación de los coeficientes</h3>


La forma matricial de los estimadores de los coeficientes del modelo es la siguiente:

\[
\hat{\boldsymbol{\beta}} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{Y}
\]

Con esta estimación, los valores ajustados \(\hat{\mathbf{Y}}\) y los residuales \(\hat{\boldsymbol{\varepsilon}}\) se calculan como:

\[
\hat{\mathbf{Y}} = \mathbf{X} \hat{\boldsymbol{\beta}}
\]

\[
\hat{\boldsymbol{\varepsilon}} = \mathbf{Y} - \hat{\mathbf{Y}}
\]




</br></br>
<div class="caja-ejemplo">
<h3>Ejemplo:</h3>
<p>

Continuando con el modelo de regresión lineal entre la **Resistencia** y la **Edad**, su representación en términos matriciales es:

\[
\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}
\]

donde:

- \( \mathbf{Y} \) es el **vector de respuesta**, que contiene los valores observados de la **Resistencia**.

- \( \mathbf{X} \) es la **matriz de diseño**, que incluye una columna de unos (para el intercepto) y una columna con los valores de la **Edad**.

- \( \boldsymbol{\beta} \) es el **vector de coeficientes**, que contiene el intercepto \( \beta_0 \) y la pendiente \( \beta_1 \).

- \( \boldsymbol{\varepsilon} \) es el **vector de errores**.




---

<br/>
1. **Matriz de diseño \( \mathbf{X} \)**: Matemáticamente, la **matriz de diseño** \( \mathbf{X} \) se expresa como se muestra a continuación,  

\[
\mathbf{X} =
\begin{bmatrix}
1 & X_{1}\\
1 & X_{2}\\
1 & X_{3}\\
1 & X_{4}\\
1 & X_{5}\\
1 & X_{6}\\
1 & X_{7}\\
1 & X_{8}\\
1 & X_{9}\\
1 & X_{10}\\
1 & X_{11}\\
1 & X_{12}\\
1 & X_{13}\\
1 & X_{14}\\
1 & X_{15}\\
1 & X_{16}\\
1 & X_{17}\\
1 & X_{18}\\
1 & X_{19}\\
1 & X_{20}
\end{bmatrix} =
\begin{bmatrix}
1 & 15.50 \\
1 & 23.75 \\
1 & 8.00 \\
1 & 17.00 \\
1 & 5.50 \\
1 & 19.00 \\
1 & 24.00 \\
1 & 2.50 \\
1 & 7.50 \\
1 & 11.00 \\
1 & 13.00 \\
1 & 3.75 \\
1 & 25.00 \\
1 & 9.75 \\
1 & 22.00 \\
1 & 18.00 \\
1 & 6.00 \\
1 & 12.50 \\
1 & 2.00 \\
1 & 21.50
\end{bmatrix}
\]


<br/>
2. **Vector de respuestas \( \mathbf{Y} \)**: El **vector de respuestas** \( \mathbf{Y} \) contiene las **resistencias observadas**, que representan la variable dependiente del modelo de **regresión lineal simple**. Matemáticamente, se expresa como sigue,  

\[
\mathbf{Y} =
\begin{bmatrix}
Y_1\\    
Y_2\\    
Y_3\\    
Y_4\\    
Y_5\\    
Y_6\\    
Y_7\\    
Y_8\\    
Y_9\\    
Y_{10}\\ 
Y_{11}\\ 
Y_{12}\\ 
Y_{13}\\ 
Y_{14}\\ 
Y_{15}\\ 
Y_{16}\\ 
Y_{17}\\ 
Y_{18}\\ 
Y_{19}\\ 
Y_{20}
\end{bmatrix} =
\begin{bmatrix}
2158.70 \\
1678.15 \\
2316.00 \\
2061.30 \\
2207.50 \\
1708.30 \\
1784.70 \\
2575.00 \\
2357.90 \\
2256.70 \\
2165.20 \\
2399.55 \\
1779.80 \\
2336.75 \\
1765.30 \\
2053.50 \\
2414.40 \\
2200.50 \\
2654.20 \\
1753.70
\end{bmatrix}
\]
 

<br/>
3. **Vector de coeficientes**: El **vector de coeficientes** \( \boldsymbol{\beta} \) contiene los **parámetros del modelo**, que incluyen el **intercepto** (\(\beta_0\)) y la **pendiente** (\(\beta_1\)).  

\[
\boldsymbol{\beta} =
\begin{bmatrix}
\beta_0 \\
\beta_1
\end{bmatrix}
\]

Sustituyendo los valores estimados en el modelo:

\[
\widehat{\boldsymbol{\beta}} =
\begin{bmatrix}
2627.82 \\
-37.15
\end{bmatrix}
\]

donde:

- \( \widehat{\beta}_0 = 2627.82 \) representa el **intercepto**.

- \( \widehat{\beta}_1 = -37.15 \) representa la **pendiente** de la recta.


<br/>
4. **Vector de residuos**: Nuevamente, insistiendo en la diferencia, en un modelo de regresión, es importante diferenciar entre los **errores** y los **residuales**:  

   - **Errores \( \boldsymbol{\varepsilon} \)**: Representan la diferencia entre los valores observados \( Y_i \) y la verdadera relación lineal de la población. 

   \[
   \varepsilon_i = Y_i - \beta_0 - \beta_1 X_i
   \]

   - **Residuos o residuales \(\hat{\boldsymbol{\varepsilon}}=\mathbf{e}\)**: Son la diferencia entre los valores observados \( Y_i \) y los valores ajustados \( \hat{Y}_i \) obtenidos con los coeficientes estimados \( \hat{\beta}_0 \) y \( \hat{\beta}_1 \). Los residuales se pueden calcular y analizar, a diferencia de los errores.

   \[
   \hat{\boldsymbol{\varepsilon}_i}= e_i = Y_i - \hat{Y}_i = Y_i - \hat{\beta}_0 - \hat{\beta}_1 X_i
   \]

   El vector de residuos se expresa como:

   \[
   \mathbf{e} =
   \begin{bmatrix}
   e_1    \\
   e_2    \\
   e_3    \\
   e_4    \\
   e_5    \\
   e_6    \\
   e_7    \\
   e_8    \\
   e_9    \\
   e_{10} \\
   e_{11} \\
   e_{12} \\
   e_{13} \\
   e_{14} \\
   e_{15} \\
   e_{16} \\
   e_{17} \\
   e_{18} \\
   e_{19} \\
   e_{20}
   \end{bmatrix}
   =
   \begin{bmatrix}
   Y_1 - \hat{\beta}_0 - \hat{\beta}_1 X_1 \\
   Y_2 - \hat{\beta}_0 - \hat{\beta}_1 X_2 \\
   Y_3 - \hat{\beta}_0 - \hat{\beta}_1 X_3 \\
   Y_4 - \hat{\beta}_0 - \hat{\beta}_1 X_4 \\
   Y_5 - \hat{\beta}_0 - \hat{\beta}_1 X_5 \\
   Y_6 - \hat{\beta}_0 - \hat{\beta}_1 X_6 \\
   Y_7 - \hat{\beta}_0 - \hat{\beta}_1 X_7 \\
   Y_8 - \hat{\beta}_0 - \hat{\beta}_1 X_8 \\
   Y_9 - \hat{\beta}_0 - \hat{\beta}_1 X_9 \\
   Y_{10} - \hat{\beta}_0 - \hat{\beta}_1 X_{10} \\
   Y_{11} - \hat{\beta}_0 - \hat{\beta}_1 X_{11} \\
   Y_{12} - \hat{\beta}_0 - \hat{\beta}_1 X_{12} \\
   Y_{13} - \hat{\beta}_0 - \hat{\beta}_1 X_{13} \\
   Y_{14} - \hat{\beta}_0 - \hat{\beta}_1 X_{14} \\
   Y_{15} - \hat{\beta}_0 - \hat{\beta}_1 X_{15} \\
   Y_{16} - \hat{\beta}_0 - \hat{\beta}_1 X_{16} \\
   Y_{17} - \hat{\beta}_0 - \hat{\beta}_1 X_{17} \\
   Y_{18} - \hat{\beta}_0 - \hat{\beta}_1 X_{18} \\
   Y_{19} - \hat{\beta}_0 - \hat{\beta}_1 X_{19} \\
   Y_{20} - \hat{\beta}_0 - \hat{\beta}_1 X_{20}
   \end{bmatrix}
   \]
   
   El vector de residuos queda como sigue:
   
   \[
   \mathbf{e} =
   \begin{bmatrix}
   106.7583  \\
   -67.2746  \\
   -14.5936  \\
   65.0887   \\
   -215.9776 \\
   -213.6041 \\
   48.5638   \\
   40.0616   \\
   8.7296    \\
   37.5671   \\
   20.3743   \\
   -88.9464  \\
   80.8174   \\
   71.1752   \\
   -45.1434  \\
   94.4423   \\
   9.4992    \\
   37.0975   \\
   100.6848  \\
   -75.3202
   \end{bmatrix}
   \]
   
   
   
   
</p>
</div>
   
   